{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarizing, you must first scale (or standardize) separately each input variable\n",
    "of your data, scale your desired output variables, and use these scaled patterns to train\n",
    "the neural network. Then, when the training is finished, you can make predictions over\n",
    "new patterns in three steps: scale the pattern, introduce it into the neural network,\n",
    "and descale the obtained output from the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import out in-house neural network class, at the beginning it will output a lot of internal debugging immediately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NeuralNet import NeuralNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L =  4\n",
      "n =  [4, 9, 5, 1]\n",
      "xi =  [array([0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0.]), array([0.])]\n",
      "xi[0] =  [0. 0. 0. 0.]\n",
      "xi[1] =  [0. 0. 0. 0.]\n",
      "wh =  [array([[0.]]), array([[0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0.]]), array([[0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0.]]), array([[0., 0., 0., 0., 0.]])]\n",
      "wh[1] =  [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "layers = [4, 9, 5, 1]\n",
    "nn = NeuralNet(layers=layers)\n",
    "\n",
    "print(\"L = \", nn.L, end=\"\\n\")\n",
    "print(\"n = \", nn.n, end=\"\\n\")\n",
    "\n",
    "print(\"xi = \", nn.xi, end=\"\\n\")\n",
    "print(\"xi[0] = \", nn.xi[0], end=\"\\n\")\n",
    "print(\"xi[1] = \", nn.xi[0], end=\"\\n\")\n",
    "\n",
    "print(\"wh = \", nn.w, end=\"\\n\")\n",
    "print(\"wh[1] = \", nn.w[1], end=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Optional: Plot the evolution of the training and validation errors\n",
    "    # Feedâˆ’forward all test patterns\n",
    "    # Descale the predictions of test patterns, and evaluate them\n",
    "    # test_predictions = self.predict(x)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
