{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You must run this notebook only if the notebook [`01-prepare-data.ipynb`](./01-prepare-data.ipynb) has been ran.\n",
    "We rely on the existence of the pre-processed dataset files to run the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load the dataset from the CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Seating Capacity  Average Meal Price  Weekend Reservations  \\\n",
      "0                38               73.98                    13   \n",
      "1                76               28.11                    48   \n",
      "2                48               48.29                    27   \n",
      "3                34               51.55                     9   \n",
      "4                88               75.98                    37   \n",
      "\n",
      "   Weekday Reservations     Revenue  Marketing&Followers  Location_Downtown  \\\n",
      "0                     4   638945.52            -0.870544              False   \n",
      "1                     6   490207.83             0.712762               True   \n",
      "2                    14   541368.62            -0.122085              False   \n",
      "3                    17   404556.80            -1.591078              False   \n",
      "4                    26  1491046.35             0.314123               True   \n",
      "\n",
      "   Location_Rural  Location_Suburban  Cuisine_American  Cuisine_French  \\\n",
      "0            True              False             False           False   \n",
      "1           False              False             False           False   \n",
      "2            True              False             False           False   \n",
      "3            True              False             False           False   \n",
      "4           False              False             False           False   \n",
      "\n",
      "   Cuisine_Indian  Cuisine_Italian  Cuisine_Japanese  Cuisine_Mexican  \n",
      "0           False            False              True            False  \n",
      "1           False            False             False             True  \n",
      "2           False             True             False            False  \n",
      "3           False             True             False            False  \n",
      "4           False            False              True            False  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('data/reduced_dataset.csv')\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading the data, we need to perform some immediate pre-processing. We cannot (in a simple way) load the already scaled values from the dataset, as we'll not be able to descale them back (in a simple way), so let's scale the columns right here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Seating Capacity  Average Meal Price  Weekend Reservations  \\\n",
      "0         -1.276714            1.819441             -0.823590   \n",
      "1          0.907389           -1.380216              0.924293   \n",
      "2         -0.701950            0.027437             -0.124437   \n",
      "3         -1.506619            0.254838             -1.023349   \n",
      "4          1.597106            1.958951              0.374958   \n",
      "\n",
      "   Weekday Reservations   Revenue  Marketing&Followers  Location_Downtown  \\\n",
      "0             -1.261571 -0.064043            -0.870544              False   \n",
      "1             -1.161586 -0.620285             0.712762               True   \n",
      "2             -0.761648 -0.428956            -0.122085              False   \n",
      "3             -0.611671 -0.940598            -1.591078              False   \n",
      "4             -0.161740  3.122598             0.314123               True   \n",
      "\n",
      "   Location_Rural  Location_Suburban  Cuisine_American  Cuisine_French  \\\n",
      "0            True              False             False           False   \n",
      "1           False              False             False           False   \n",
      "2            True              False             False           False   \n",
      "3            True              False             False           False   \n",
      "4           False              False             False           False   \n",
      "\n",
      "   Cuisine_Indian  Cuisine_Italian  Cuisine_Japanese  Cuisine_Mexican  \n",
      "0           False            False              True            False  \n",
      "1           False            False             False             True  \n",
      "2           False             True             False            False  \n",
      "3           False             True             False            False  \n",
      "4           False            False              True            False  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# list of columns ONLY for the REDUCED dataset\n",
    "columns_to_normalize = ['Revenue', 'Seating Capacity', 'Average Meal Price', 'Weekend Reservations', 'Weekday Reservations']\n",
    "data[columns_to_normalize] = scaler.fit_transform(data[columns_to_normalize])\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "#list of columns for the full dataset\n",
    "columns_to_normalize = ['Revenue', 'Seating Capacity', 'Average Meal Price', 'Weekend Reservations', 'Weekday Reservations', 'Marketing&Followers', 'Chef Experience Years', 'Number of Reviews', 'Avg Review Length', 'Ambience Score', 'Service Quality Score', 'Rating']\n",
    "scaler = StandardScaler()\n",
    "data_copy[columns_to_normalize] = scaler.fit_transform(data_copy[columns_to_normalize])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarizing, you must first scale (or standardize) separately each input variable\n",
    "of your data, scale your desired output variables, and use these scaled patterns to train\n",
    "the neural network. Then, when the training is finished, you can make predictions over\n",
    "new patterns in three steps: scale the pattern, introduce it into the neural network,\n",
    "and descale the obtained output from the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import out in-house neural network class, at the beginning it will output a lot of internal debugging immediately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NeuralNet import NeuralNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L =  4\n",
      "n =  [4, 9, 5, 1]\n",
      "xi =  [array([0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0.]), array([0.])]\n",
      "xi[0] =  [0. 0. 0. 0.]\n",
      "xi[1] =  [0. 0. 0. 0.]\n",
      "wh =  [array([[0.]]), array([[0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0.]]), array([[0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0.]]), array([[0., 0., 0., 0., 0.]])]\n",
      "wh[1] =  [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "layers = [4, 9, 5, 1]\n",
    "nn = NeuralNet(layers=layers)\n",
    "\n",
    "print(\"L = \", nn.L, end=\"\\n\")\n",
    "print(\"n = \", nn.n, end=\"\\n\")\n",
    "\n",
    "print(\"xi = \", nn.xi, end=\"\\n\")\n",
    "print(\"xi[0] = \", nn.xi[0], end=\"\\n\")\n",
    "print(\"xi[1] = \", nn.xi[0], end=\"\\n\")\n",
    "\n",
    "print(\"wh = \", nn.w, end=\"\\n\")\n",
    "print(\"wh[1] = \", nn.w[1], end=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Optional: Plot the evolution of the training and validation errors\n",
    "    # Feedâˆ’forward all test patterns\n",
    "    # Descale the predictions of test patterns, and evaluate them\n",
    "    # test_predictions = self.predict(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
